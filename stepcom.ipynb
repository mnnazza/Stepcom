{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mnnazza/stepcom?scriptVersionId=283216320\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"0b521f77","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-12-01T21:08:29.061813Z","iopub.status.busy":"2025-12-01T21:08:29.061502Z","iopub.status.idle":"2025-12-01T21:08:34.063085Z","shell.execute_reply":"2025-12-01T21:08:34.06204Z"},"papermill":{"duration":5.011096,"end_time":"2025-12-01T21:08:34.064646","exception":false,"start_time":"2025-12-01T21:08:29.05355","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úîÔ∏è Gemini configured. google-generativeai version: 0.8.5\n"]}],"source":["import os, time, random, json, traceback\n","from datetime import datetime, timedelta\n","\n","import google.generativeai as genai\n","from kaggle_secrets import UserSecretsClient\n","\n","# get secret\n","user_secrets = UserSecretsClient()\n","secret_value = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n","if not secret_value:\n","    raise ValueError(\"Secret 'GOOGLE_API_KEY' not found in Kaggle Secrets. Add it and re-run this cell.\")\n","\n","os.environ[\"GOOGLE_API_KEY\"] = secret_value\n","try:\n","    genai.configure(api_key=secret_value)\n","except Exception:\n","    pass\n","\n","print(\"‚úîÔ∏è Gemini configured. google-generativeai version:\", getattr(genai, \"__version__\", \"unknown\"))"]},{"cell_type":"markdown","id":"537253a2","metadata":{"papermill":{"duration":0.005225,"end_time":"2025-12-01T21:08:34.075321","exception":false,"start_time":"2025-12-01T21:08:34.070096","status":"completed"},"tags":[]},"source":["**Cell 1 - Environment Setup & Gemini SDK Configuration**\n","\n","This cell initializes everything required for Stepcom to run inside Kaggle.\n","\n","What this cell does\n","\n","Imports core Python libraries (os, json, datetime, etc.).\n","\n","Retrieves GOOGLE_API_KEY securely via Kaggle Secrets (no hard-coded keys).\n","\n","Sets up the environment variable and configures the Gemini SDK.\n","\n","Verifies installation by printing the SDK version.\n","\n","Why this matters\n","\n","Every other component - including model detection, agents, memory, and UI - depend on the Gemini client being initialized here.\n","If this cell fails, nothing else will work."]},{"cell_type":"code","execution_count":2,"id":"5bb4b82e","metadata":{"execution":{"iopub.execute_input":"2025-12-01T21:08:34.086612Z","iopub.status.busy":"2025-12-01T21:08:34.086193Z","iopub.status.idle":"2025-12-01T21:08:34.094925Z","shell.execute_reply":"2025-12-01T21:08:34.093916Z"},"papermill":{"duration":0.016369,"end_time":"2025-12-01T21:08:34.096453","exception":false,"start_time":"2025-12-01T21:08:34.080084","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["‚ÑπÔ∏è types present but HttpRetryOptions not available. Using fallback retries.\n","Retry helper ready. USE_HTTP_RETRY= False\n"]}],"source":["USE_HTTP_RETRY = False\n","retry_config = None\n","try:\n","    from google.generativeai import types\n","    if hasattr(types, \"HttpRetryOptions\"):\n","        retry_config = types.HttpRetryOptions(\n","            attempts=5, exp_base=2, initial_delay=1.0,\n","            http_status_codes=[429,500,503,504]\n","        )\n","        USE_HTTP_RETRY = True\n","        print(\"‚úîÔ∏è Using official HttpRetryOptions for retries.\")\n","    else:\n","        print(\"‚ÑπÔ∏è types present but HttpRetryOptions not available. Using fallback retries.\")\n","except Exception:\n","    print(\"‚ÑπÔ∏è google.generativeai.types not available. Using fallback retries.\")\n","\n","# fallback retry helper\n","def send_with_retries(chat_obj, prompt, max_attempts=5, initial_delay=1.0, backoff=2.0, jitter=0.2):\n","    attempt = 0\n","    delay = initial_delay\n","    last_exc = None\n","    while attempt < max_attempts:\n","        try:\n","            return chat_obj.send_message(prompt)\n","        except Exception as e:\n","            last_exc = e\n","            attempt += 1\n","            if attempt >= max_attempts:\n","                raise\n","            sleep_time = max(0.1, delay + random.uniform(-jitter*delay, jitter*delay))\n","            print(f\"[fallback-retry] attempt {attempt}/{max_attempts} failed: {type(e).__name__}: {e}\")\n","            print(f\"  ‚Üí retrying in {sleep_time:.2f}s...\")\n","            time.sleep(sleep_time)\n","            delay *= backoff\n","    if last_exc:\n","        raise last_exc\n","\n","print(\"Retry helper ready. USE_HTTP_RETRY=\", USE_HTTP_RETRY)"]},{"cell_type":"markdown","id":"5dce1b47","metadata":{"papermill":{"duration":0.004906,"end_time":"2025-12-01T21:08:34.106554","exception":false,"start_time":"2025-12-01T21:08:34.101648","status":"completed"},"tags":[]},"source":["**Cell 2 - Retry Logic (Official + Fallback)**\n","\n","This cell detects whether Google‚Äôs official HttpRetryOptions is available.\n","If not, Stepcom uses a flexible fallback retry handler.\n","\n","Responsibilities\n","\n","Enables stable API connections.\n","\n","Prevents failures due to rate limits, slow network, or transient errors.\n","\n","Provides exponential backoff, jitter, and max retry attempts.\n","\n","Why it matters\n","\n","Kaggle notebooks occasionally face network instability - this ensures Stepcom works smoothly even under quota or connection issues."]},{"cell_type":"code","execution_count":3,"id":"69428182","metadata":{"execution":{"iopub.execute_input":"2025-12-01T21:08:34.117852Z","iopub.status.busy":"2025-12-01T21:08:34.117592Z","iopub.status.idle":"2025-12-01T21:08:36.175954Z","shell.execute_reply":"2025-12-01T21:08:36.174804Z"},"papermill":{"duration":2.066152,"end_time":"2025-12-01T21:08:36.177609","exception":false,"start_time":"2025-12-01T21:08:34.111457","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Listing models available to this API key (may take a second)...\n","01. models/embedding-gecko-001\n","02. models/gemini-2.5-pro-preview-03-25\n","03. models/gemini-2.5-flash\n","04. models/gemini-2.5-pro-preview-05-06\n","05. models/gemini-2.5-pro-preview-06-05\n","06. models/gemini-2.5-pro\n","07. models/gemini-2.0-flash-exp\n","08. models/gemini-2.0-flash\n","09. models/gemini-2.0-flash-001\n","10. models/gemini-2.0-flash-exp-image-generation\n","11. models/gemini-2.0-flash-lite-001\n","12. models/gemini-2.0-flash-lite\n","13. models/gemini-2.0-flash-lite-preview-02-05\n","14. models/gemini-2.0-flash-lite-preview\n","15. models/gemini-2.0-pro-exp\n","16. models/gemini-2.0-pro-exp-02-05\n","17. models/gemini-exp-1206\n","18. models/gemini-2.0-flash-thinking-exp-01-21\n","19. models/gemini-2.0-flash-thinking-exp\n","20. models/gemini-2.0-flash-thinking-exp-1219\n","21. models/gemini-2.5-flash-preview-tts\n","22. models/gemini-2.5-pro-preview-tts\n","23. models/learnlm-2.0-flash-experimental\n","24. models/gemma-3-1b-it\n","25. models/gemma-3-4b-it\n","26. models/gemma-3-12b-it\n","27. models/gemma-3-27b-it\n","28. models/gemma-3n-e4b-it\n","29. models/gemma-3n-e2b-it\n","30. models/gemini-flash-latest\n","31. models/gemini-flash-lite-latest\n","32. models/gemini-pro-latest\n","33. models/gemini-2.5-flash-lite\n","34. models/gemini-2.5-flash-image-preview\n","35. models/gemini-2.5-flash-image\n","36. models/gemini-2.5-flash-preview-09-2025\n","37. models/gemini-2.5-flash-lite-preview-09-2025\n","38. models/gemini-3-pro-preview\n","39. models/gemini-3-pro-image-preview\n","40. models/nano-banana-pro-preview\n","41. models/gemini-robotics-er-1.5-preview\n","42. models/gemini-2.5-computer-use-preview-10-2025\n","43. models/embedding-001\n","44. models/text-embedding-004\n","45. models/gemini-embedding-exp-03-07\n","46. models/gemini-embedding-exp\n","47. models/gemini-embedding-001\n","48. models/aqa\n","49. models/imagen-4.0-generate-preview-06-06\n","50. models/imagen-4.0-ultra-generate-preview-06-06\n","\n","Trying candidate models (stops on first success)\n","Trying models/gemini-2.5-flash\n","‚Üí success with models/gemini-2.5-flash preview: Hi!\n","Selected model: models/gemini-2.5-flash\n"]}],"source":["MODEL_NAME_PATH = \"/kaggle/working/stepcom_model_name.txt\"\n","\n","print(\"Listing models available to this API key (may take a second)...\")\n","try:\n","    models = genai.list_models()\n","    model_names = []\n","    for m in models:\n","        try:\n","            model_names.append(m.name if hasattr(m, \"name\") else str(m))\n","        except Exception:\n","            model_names.append(str(m))\n","    model_names = list(dict.fromkeys(model_names))\n","    for i,nm in enumerate(model_names[:50], start=1):\n","        print(f\"{i:02d}. {nm}\")\n","except Exception as e:\n","    print(\"Could not list models:\", e)\n","    model_names = []\n","\n","# candidate selection: prefer gemini flash/pro or gemini-flash-latest\n","candidates = []\n","for nm in model_names:\n","    ln = nm.lower()\n","    if \"gemini\" in ln and \"flash\" in ln:\n","        candidates.append(nm)\n","for nm in model_names:\n","    if nm not in candidates:\n","        candidates.append(nm)\n","for nm in [\"models/gemini-2.5-flash\",\"models/gemini-pro-latest\",\"models/gemini-flash-latest\"]:\n","    if nm not in candidates:\n","        candidates.append(nm)\n","\n","print(\"\\nTrying candidate models (stops on first success)\")\n","used_model = None\n","for cand in candidates[:15]:\n","    print(\"Trying\", cand)\n","    try:\n","        if USE_HTTP_RETRY and retry_config is not None:\n","            model = genai.GenerativeModel(model_name=cand, system_instruction=\"You are StepCom - concise and kind.\", http_retry=retry_config)\n","        else:\n","            model = genai.GenerativeModel(model_name=cand, system_instruction=\"You are StepCom - concise and kind.\")\n","        chat = model.start_chat(history=[])\n","        try:\n","            if USE_HTTP_RETRY:\n","                resp = chat.send_message(\"Test: say hi\")\n","            else:\n","                resp = send_with_retries(chat, \"Test: say hi\")\n","            text = getattr(resp, \"text\", str(resp))\n","            print(\"‚Üí success with\", cand, \"preview:\", text[:120])\n","            used_model = cand\n","            break\n","        except Exception as e:\n","            print(\" model call failed:\", type(e).__name__, e)\n","    except Exception as e:\n","        print(\" create model failed:\", type(e).__name__, e)\n","\n","if not used_model:\n","    used_model = \"models/gemini-2.5-flash\"\n","\n","with open(MODEL_NAME_PATH, \"w\") as f:\n","    f.write(used_model)\n","\n","MODEL_NAME = used_model\n","print(\"Selected model:\", MODEL_NAME)"]},{"cell_type":"markdown","id":"a14da0a9","metadata":{"papermill":{"duration":0.005302,"end_time":"2025-12-01T21:08:36.18915","exception":false,"start_time":"2025-12-01T21:08:36.183848","status":"completed"},"tags":[]},"source":["**Cell 3 - Automatic Model Selection**\n","\n","This cell scans all Gemini models available to the user‚Äôs API key and automatically selects the best-performing chat model.\n","\n","What it does\n","\n","Lists all models accessible via your key.\n","\n","Prioritizes fast + capable Gemini Flash models.\n","\n","Runs a test conversation with each candidate model.\n","\n","Saves the working model to:\n","/kaggle/working/stepcom_model_name.txt\n","\n","Why it matters\n","\n","Every user's API plan gives access to different models.\n","This auto-selection guarantees Stepcom chooses a working model instead of failing with 404 or quota issues."]},{"cell_type":"code","execution_count":4,"id":"aed1f5b4","metadata":{"execution":{"iopub.execute_input":"2025-12-01T21:08:36.202344Z","iopub.status.busy":"2025-12-01T21:08:36.201981Z","iopub.status.idle":"2025-12-01T21:08:36.212213Z","shell.execute_reply":"2025-12-01T21:08:36.211096Z"},"papermill":{"duration":0.018538,"end_time":"2025-12-01T21:08:36.213792","exception":false,"start_time":"2025-12-01T21:08:36.195254","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Memory loaded. Mode: soft\n"]}],"source":["MEMORY_PATH = \"/kaggle/working/stepcom_memory.json\"\n","EXPLAIN_CACHE_PATH = \"/kaggle/working/stepcom_explain_cache.json\"\n","\n","default_memory = {\n","    \"tasks\": [],\n","    \"completed\": [],\n","    \"goals\": [],\n","    \"habits\": {},\n","    \"meta\": {\"mode\": \"soft\", \"excuse_count\": 0, \"a2a_logs\": []}\n","}\n","\n","def load_json(path, default):\n","    if os.path.exists(path):\n","        try:\n","            with open(path, \"r\") as f:\n","                return json.load(f)\n","        except Exception as e:\n","            print(\"Warning loading\", path, \":\", e)\n","            return default\n","    return default\n","\n","def save_json(path, obj):\n","    with open(path, \"w\") as f:\n","        json.dump(obj, f, indent=2, default=str)\n","\n","memory = load_json(MEMORY_PATH, default_memory.copy())\n","explain_cache = load_json(EXPLAIN_CACHE_PATH, {})\n","print(\"Memory loaded. Mode:\", memory[\"meta\"].get(\"mode\",\"soft\"))"]},{"cell_type":"markdown","id":"d21fd1be","metadata":{"papermill":{"duration":0.005431,"end_time":"2025-12-01T21:08:36.224753","exception":false,"start_time":"2025-12-01T21:08:36.219322","status":"completed"},"tags":[]},"source":["**Cell 4 - Memory System (Persistent JSON Storage)**\n","\n","This cell creates and loads Stepcom‚Äôs long-term memory files.\n","\n","Files created\n","\n","stepcom_memory.json\n","\n","stepcom_explain_cache.json\n","\n","What Stepcom remembers\n","\n","Habits (good & bad)\n","\n","Tasks & completions\n","\n","Goals (if user mentions them)\n","\n","Explanations cached (so Gemini isn‚Äôt called repeatedly)\n","\n","Emotion/Plan agent logs\n","\n","Why this matters\n","\n","Memory enables Stepcom to behave like a consistent, caring productivity partner who knows your patterns and follows up naturally."]},{"cell_type":"code","execution_count":5,"id":"f40451ce","metadata":{"execution":{"iopub.execute_input":"2025-12-01T21:08:36.237064Z","iopub.status.busy":"2025-12-01T21:08:36.236505Z","iopub.status.idle":"2025-12-01T21:08:36.242394Z","shell.execute_reply":"2025-12-01T21:08:36.241501Z"},"papermill":{"duration":0.013747,"end_time":"2025-12-01T21:08:36.243732","exception":false,"start_time":"2025-12-01T21:08:36.229985","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Observability helper ready.\n"]}],"source":["def log_a2a_call(agent, prompt, response):\n","    entry = {\"agent\": agent, \"prompt\": (prompt or \"\")[:800], \"response\": (response or \"\")[:2000], \"ts\": datetime.now().isoformat()}\n","    memory[\"meta\"].setdefault(\"a2a_logs\", []).append(entry)\n","    save_json(MEMORY_PATH, memory)\n","\n","print(\"Observability helper ready.\")"]},{"cell_type":"markdown","id":"668e2096","metadata":{"papermill":{"duration":0.005164,"end_time":"2025-12-01T21:08:36.254485","exception":false,"start_time":"2025-12-01T21:08:36.249321","status":"completed"},"tags":[]},"source":["**Cell 5 - Observability Logging**\n","\n","This cell logs every internal A2A (Agent-to-Agent) call.\n","\n","What gets logged\n","\n","Timestamp\n","\n","Agent name (EmotionAgent / PlanAgent / Controller)\n","\n","Prompt sent\n","\n","Response generated\n","\n","Why it matters\n","\n","This gives transparency in agent behaviour, helps debugging issues, and is required for Kaggle Capstone evaluation."]},{"cell_type":"code","execution_count":6,"id":"07cd9ca2","metadata":{"execution":{"iopub.execute_input":"2025-12-01T21:08:36.266682Z","iopub.status.busy":"2025-12-01T21:08:36.266403Z","iopub.status.idle":"2025-12-01T21:08:36.277483Z","shell.execute_reply":"2025-12-01T21:08:36.2768Z"},"papermill":{"duration":0.019315,"end_time":"2025-12-01T21:08:36.278941","exception":false,"start_time":"2025-12-01T21:08:36.259626","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Core tools ready.\n"]}],"source":["def add_task(task: str):\n","    if not task: return \"No task provided.\"\n","    memory.setdefault(\"tasks\", []).append({\"task\": task, \"added\": datetime.now().isoformat()})\n","    save_json(MEMORY_PATH, memory)\n","    return f\"Added task: {task} ‚ú®\"\n","\n","def complete_task(task: str):\n","    for t in list(memory.get(\"tasks\", [])):\n","        if t[\"task\"].strip().lower() == task.strip().lower():\n","            memory.setdefault(\"completed\", []).append({\"task\": task, \"completed\": datetime.now().isoformat()})\n","            memory[\"tasks\"].remove(t)\n","            save_json(MEMORY_PATH, memory)\n","            return f\"Completed: {task} üéâ\"\n","    return \"Couldn't find that task.\"\n","\n","def add_goal(goal: str):\n","    if not goal: return \"No goal provided.\"\n","    memory.setdefault(\"goals\", []).append(goal)\n","    save_json(MEMORY_PATH, memory)\n","    return f\"Saved goal: {goal} üåü\"\n","\n","def add_habit(name: str, kind: str):\n","    if not name or not kind: return \"Usage: add_habit(name, kind)\"\n","    kind = kind.lower()\n","    if kind not in (\"good\",\"bad\"): return \"Habit type must be 'good' or 'bad'.\"\n","    memory.setdefault(\"habits\", {})[name] = {\"type\": kind, \"streak\": 0, \"last_done\": None, \"notes\": []}\n","    save_json(MEMORY_PATH, memory)\n","    return f\"Habit '{name}' added as a {kind} habit.\"\n","\n","def mark_habit_done(name: str):\n","    h = memory.get(\"habits\", {}).get(name)\n","    if not h: return \"Habit not found.\"\n","    now = datetime.now()\n","    last_iso = h.get(\"last_done\")\n","    last = None\n","    if last_iso:\n","        try:\n","            last = datetime.fromisoformat(last_iso)\n","        except:\n","            last = None\n","    if last and (now.date() - last.date()) == timedelta(days=1):\n","        h[\"streak\"] += 1\n","    else:\n","        if last and now.date() == last.date():\n","            pass\n","        else:\n","            h[\"streak\"] = 1\n","    h[\"last_done\"] = now.isoformat()\n","    h.setdefault(\"notes\", []).append({\"done\": now.isoformat()})\n","    save_json(MEMORY_PATH, memory)\n","    return f\"Marked '{name}' done. Streak: {h['streak']} üå±\"\n","\n","def get_habits():\n","    return memory.get(\"habits\", {})\n","\n","print(\"Core tools ready.\")"]},{"cell_type":"markdown","id":"90922e52","metadata":{"papermill":{"duration":0.005317,"end_time":"2025-12-01T21:08:36.291081","exception":false,"start_time":"2025-12-01T21:08:36.285764","status":"completed"},"tags":[]},"source":["**Cell 6 - Core Internal Tools**\n","\n","These are backend functions that StepCom can trigger autonomously when needed.\n","\n","Includes\n","\n","Add task\n","\n","Mark task completed\n","\n","Save goal\n","\n","Add habit (good or bad)\n","\n","Mark habit done\n","\n","Retrieve habits\n","\n","Why it matters\n","\n","Even though the UI is chat-only, Stepcom still needs to store structured habit/task data internally to track user progress."]},{"cell_type":"code","execution_count":7,"id":"a80c236c","metadata":{"execution":{"iopub.execute_input":"2025-12-01T21:08:36.303187Z","iopub.status.busy":"2025-12-01T21:08:36.302633Z","iopub.status.idle":"2025-12-01T21:08:36.313134Z","shell.execute_reply":"2025-12-01T21:08:36.312082Z"},"papermill":{"duration":0.018403,"end_time":"2025-12-01T21:08:36.314676","exception":false,"start_time":"2025-12-01T21:08:36.296273","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Response helpers ready.\n"]}],"source":["import re, html\n","FILLERS = r\"\\b(um+|uh+|hmm+|huh+|erm+|like)\\b\"\n","def normalize_input(s: str) -> str:\n","    if not s: return s\n","    s2 = re.sub(FILLERS, \"\", s, flags=re.IGNORECASE)\n","    s2 = re.sub(r\"\\s{2,}\", \" \", s2).strip()\n","    s2 = re.sub(r\"\\.{2,}\", \".\", s2)\n","    s2 = s2.strip(\" \\t\\n\\r-‚Äì‚Äî:;\")\n","    return s2 if s2 else s\n","\n","def extract_text(resp):\n","    try:\n","        txt = getattr(resp, \"text\", None)\n","        if txt and isinstance(txt, str) and txt.strip():\n","            return txt.strip()\n","    except Exception:\n","        pass\n","    try:\n","        if hasattr(resp, \"to_dict\"):\n","            d = resp.to_dict()\n","        elif isinstance(resp, dict):\n","            d = resp\n","        else:\n","            return str(resp)\n","        for key in (\"content\",\"contents\",\"output\",\"text\"):\n","            if key in d:\n","                v = d[key]\n","                if isinstance(v, str) and v.strip():\n","                    return v.strip()\n","                if isinstance(v, list):\n","                    parts = []\n","                    for part in v:\n","                        if isinstance(part, dict) and \"text\" in part:\n","                            parts.append(part[\"text\"])\n","                        elif isinstance(part, str):\n","                            parts.append(part)\n","                    if parts:\n","                        return \"\\n\".join(parts)[:4000]\n","    except Exception:\n","        try:\n","            return str(resp)\n","        except:\n","            return \"<unreadable response>\"\n","    try:\n","        return str(resp)\n","    except:\n","        return \"<no textual content>\"\n","\n","print(\"Response helpers ready.\")"]},{"cell_type":"markdown","id":"e9d50c52","metadata":{"papermill":{"duration":0.00558,"end_time":"2025-12-01T21:08:36.326422","exception":false,"start_time":"2025-12-01T21:08:36.320842","status":"completed"},"tags":[]},"source":["**Cell 7 - Input Cleaning & Response Extraction**\n","\n","This cell ensures user messages are clean and model responses are extracted safely.\n","\n","Main functions\n","\n","Removes fillers (‚Äúumm‚Äù, ‚Äúlike‚Äù, ‚Äúhmm‚Äù) for cleaner conversations.\n","\n","Extracts clean text from complex Gemini responses.\n","\n","Handles edge cases where responses include lists, dicts, and nested nodes.\n","\n","Why it matters\n","\n","Reduces model confusion and prevents UI glitches."]},{"cell_type":"code","execution_count":8,"id":"e764c628","metadata":{"execution":{"iopub.execute_input":"2025-12-01T21:08:36.338737Z","iopub.status.busy":"2025-12-01T21:08:36.338463Z","iopub.status.idle":"2025-12-01T21:08:36.352363Z","shell.execute_reply":"2025-12-01T21:08:36.351317Z"},"papermill":{"duration":0.021963,"end_time":"2025-12-01T21:08:36.353749","exception":false,"start_time":"2025-12-01T21:08:36.331786","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["EmotionAgent and PlanAgent instantiated using model: models/gemini-2.5-flash\n","A2A delegation ready.\n"]}],"source":["emotion_system = \"\"\"\n","You are EmotionAgent for StepCom: produce one empathetic validation sentence, provide the required emotional support,\n","one grounding exercise (<=3 steps), and an offer: 'Would you like a tiny plan?'\n","Keep it short and kind.\n","\"\"\"\n","plan_system = \"\"\"\n","You are PlanAgent for StepCom: produce a 1-sentence micro-goal and 2-3 time-bound micro-steps (<=10 min each), plus a check-in phrase.\n","Keep it concise and action-focused.\n","\"\"\"\n","\n","try:\n","    from google.generativeai import types as _types\n","    has_http_retry = hasattr(_types, \"HttpRetryOptions\")\n","except Exception:\n","    has_http_retry = False\n","\n","if has_http_retry and retry_config is not None:\n","    EmotionAgent = genai.GenerativeModel(model_name=MODEL_NAME, system_instruction=emotion_system, http_retry=retry_config)\n","    PlanAgent = genai.GenerativeModel(model_name=MODEL_NAME, system_instruction=plan_system, http_retry=retry_config)\n","else:\n","    EmotionAgent = genai.GenerativeModel(model_name=MODEL_NAME, system_instruction=emotion_system)\n","    PlanAgent = genai.GenerativeModel(model_name=MODEL_NAME, system_instruction=plan_system)\n","\n","print(\"EmotionAgent and PlanAgent instantiated using model:\", MODEL_NAME)\n","\n","def call_emotion_agent(user_text: str):\n","    prompt = f\"User says: '''{user_text}'''\\nRespond per your instructions.\"\n","    try:\n","        chat = EmotionAgent.start_chat(history=[])\n","        if not has_http_retry and 'send_with_retries' in globals():\n","            resp = send_with_retries(chat, prompt)\n","        else:\n","            resp = chat.send_message(prompt)\n","        text = extract_text(resp)\n","    except Exception as e:\n","        text = f\"[EmotionAgent error: {type(e).__name__}]\"\n","        traceback.print_exc()\n","    log_a2a_call(\"EmotionAgent\", prompt, text)\n","    return text\n","\n","def call_plan_agent(task_text: str):\n","    prompt = f\"User task/goal: '''{task_text}'''\\nReturn micro-plan.\"\n","    try:\n","        chat = PlanAgent.start_chat(history=[])\n","        if not has_http_retry and 'send_with_retries' in globals():\n","            resp = send_with_retries(chat, prompt)\n","        else:\n","            resp = chat.send_message(prompt)\n","        text = extract_text(resp)\n","    except Exception as e:\n","        text = f\"[PlanAgent error: {type(e).__name__}]\"\n","        traceback.print_exc()\n","    log_a2a_call(\"PlanAgent\", prompt, text)\n","    return text\n","\n","def controller_delegate_demo(user_input: str):\n","    # returns None or A2A combined response\n","    try:\n","        u = normalize_input(user_input or \"\")\n","        l = u.lower()\n","        emotional = any(k in l for k in [\"i'm sad\",\"i'm struggling\",\"i can't\",\"i cant\",\"depressed\",\"anxious\",\"lonely\",\"overwhelmed\",\"i'm overwhelmed\",\"i'm stressed\",\"i'm stressed out\"])\n","        planning  = any(k in l for k in [\"task\",\"finish\",\"project\",\"study\",\"assignment\",\"exam\",\"homework\",\"plan\",\"start\",\"deadline\",\"due\"])\n","        # if emotional -> EmotionAgent; optionally PlanAgent if it looks like planning too\n","        if emotional:\n","            emo = call_emotion_agent(u)\n","            if planning:\n","                plan = call_plan_agent(u)\n","                return emo + \"\\n\\nPlan:\\n\" + plan\n","            return emo\n","        return None\n","    except Exception as e:\n","        traceback.print_exc()\n","        return \"[A2A delegation error: couldn't process request]\"\n","\n","print(\"A2A delegation ready.\")"]},{"cell_type":"markdown","id":"db4b88e3","metadata":{"papermill":{"duration":0.005402,"end_time":"2025-12-01T21:08:36.364811","exception":false,"start_time":"2025-12-01T21:08:36.359409","status":"completed"},"tags":[]},"source":["**Cell 8 - EmotionAgent & PlanAgent**\n","\n","Two specialized micro-agents are defined here:\n","\n","EmotionAgent\n","\n","Gives warmth, empathy, grounding exercises\n","\n","Helps users who feel stressed, overwhelmed, anxious\n","\n","PlanAgent\n","\n","Produces tiny 2‚Äì3 step micro-plans\n","\n","Focused on completing small tasks quickly (Gen Z style)\n","\n","Controller Delegate Logic\n","\n","Automatically triggers:\n","\n","EmotionAgent when message contains emotional distress\n","\n","PlanAgent when message contains task-related triggers\n","\n","Both when message mixes emotion + task\n","\n","Why this matters\n","\n","This makes Stepcom feel like a real companion, not just a chatbot, but a system that understands the emotional + productivity context. "]},{"cell_type":"code","execution_count":9,"id":"8eb9cc15","metadata":{"execution":{"iopub.execute_input":"2025-12-01T21:08:36.377264Z","iopub.status.busy":"2025-12-01T21:08:36.376708Z","iopub.status.idle":"2025-12-01T21:08:36.643718Z","shell.execute_reply":"2025-12-01T21:08:36.642505Z"},"papermill":{"duration":0.275105,"end_time":"2025-12-01T21:08:36.645343","exception":false,"start_time":"2025-12-01T21:08:36.370238","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Controller created with model: models/gemini-2.5-flash\n"]}],"source":["MASTER_PROMPT = \"\"\"\n","You are Stepcom ‚Äî the user's AI productivity companion and friend.\n","Tone: Gen-Z friendly, gentle but real. Provide one tiny action <=10 minutes.\n","When user shares habits or task-like sentences, you may ask to save them internally.\n","When user reports completion, mark it. When asked, explain pros/cons for habits.\n","Do not create UI elements ‚Äî operate through chat only. Keep responses short, warm, and actionable.\n","\"\"\"\n","\n","tools = [add_task, complete_task, add_goal, add_habit, mark_habit_done, get_habits]\n","\n","if has_http_retry and retry_config is not None:\n","    controller_model = genai.GenerativeModel(model_name=MODEL_NAME, system_instruction=MASTER_PROMPT, tools=tools, http_retry=retry_config)\n","else:\n","    controller_model = genai.GenerativeModel(model_name=MODEL_NAME, system_instruction=MASTER_PROMPT, tools=tools)\n","\n","controller_chat = controller_model.start_chat(history=[])\n","print(\"Controller created with model:\", MODEL_NAME)"]},{"cell_type":"markdown","id":"b92cbdbe","metadata":{"papermill":{"duration":0.005385,"end_time":"2025-12-01T21:08:36.656651","exception":false,"start_time":"2025-12-01T21:08:36.651266","status":"completed"},"tags":[]},"source":["**Cell 9 - Main Controller Model**\n","\n","This is the brain of StepCom.\n","\n","What it does\n","\n","Integrates all tools + system prompts.\n","\n","Enforces Stepcom‚Äôs personality:\n","\n","Gen-Z friendly\n","\n","Warm but real\n","\n","Helpful accountability\n","\n","Always gives a tiny actionable step\n","\n","Processes all chat messages not handled by A2A agents.\n","\n","Why it matters\n","\n","This is the core intelligence layer responsible for keeping messages consistent, helpful, and on brand."]},{"cell_type":"code","execution_count":10,"id":"c45000c1","metadata":{"execution":{"iopub.execute_input":"2025-12-01T21:08:36.669233Z","iopub.status.busy":"2025-12-01T21:08:36.668534Z","iopub.status.idle":"2025-12-01T21:08:36.675986Z","shell.execute_reply":"2025-12-01T21:08:36.674936Z"},"papermill":{"duration":0.015397,"end_time":"2025-12-01T21:08:36.677452","exception":false,"start_time":"2025-12-01T21:08:36.662055","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["explain_habit_with_gemini ready.\n"]}],"source":["def explain_habit_with_gemini(name: str):\n","    if name in explain_cache:\n","        return explain_cache[name]\n","    h = memory.get(\"habits\", {}).get(name)\n","    if not h:\n","        return \"Habit not found.\"\n","    kind = h[\"type\"]\n","    prompt = f\"\"\"\n","You are a compassionate Gen-Z friend. For the habit named '{name}' (type: {kind}), produce:\n","1) Two concise PROS (if good) OR two concise CONS (if bad).\n","2) Two short reasons/examples (<=1 sentence each).\n","3) One tiny 3-step micro-action the user can do today to reinforce/reduce it.\n","Keep tone friendly, validating, and actionable. Max 6 lines.\n","\"\"\"\n","    try:\n","        if has_http_retry and retry_config is not None:\n","            explain_model = genai.GenerativeModel(model_name=MODEL_NAME, http_retry=retry_config)\n","        else:\n","            explain_model = genai.GenerativeModel(model_name=MODEL_NAME)\n","        chat = explain_model.start_chat(history=[])\n","        if not has_http_retry and 'send_with_retries' in globals():\n","            resp = send_with_retries(chat, prompt)\n","        else:\n","            resp = chat.send_message(prompt)\n","        text = extract_text(resp)\n","    except Exception as e:\n","        text = f\"Error generating habit explanation: {type(e).__name__}: {e}\"\n","    explain_cache[name] = text\n","    save_json(EXPLAIN_CACHE_PATH, explain_cache)\n","    return text\n","\n","print(\"explain_habit_with_gemini ready.\")"]},{"cell_type":"markdown","id":"843a6ed9","metadata":{"papermill":{"duration":0.005564,"end_time":"2025-12-01T21:08:36.688767","exception":false,"start_time":"2025-12-01T21:08:36.683203","status":"completed"},"tags":[]},"source":["**Cell 10 - Habit Explanation Engine**\n","\n","This cell builds the module that:\n","\n","Generates\n","\n","Pros of good habits\n","\n","Cons of bad habits\n","\n","Real examples\n","\n","A 3-step micro action\n","\n","Features\n","\n","Uses caching to avoid repeating API calls\n","\n","Integrates into Stepcom‚Äôs chat flow naturally\n","\n","Why it matters\n","\n","It transforms Stepcom into a true improvement coach - not only tracking habits, but explaining and motivating change."]},{"cell_type":"code","execution_count":11,"id":"b26c54e7","metadata":{"execution":{"iopub.execute_input":"2025-12-01T21:08:36.701258Z","iopub.status.busy":"2025-12-01T21:08:36.700829Z","iopub.status.idle":"2025-12-01T21:08:36.707144Z","shell.execute_reply":"2025-12-01T21:08:36.706263Z"},"papermill":{"duration":0.014558,"end_time":"2025-12-01T21:08:36.708721","exception":false,"start_time":"2025-12-01T21:08:36.694163","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Personality helpers ready.\n"]}],"source":["import random\n","\n","def motivation_of_day():\n","    items = [\n","        \"Start tiny. Future-you will be thankful.\",\n","        \"5 minutes today > 0 minutes. Start now.\",\n","        \"Consistency > intensity. One small step.\"\n","    ]\n","    return random.choice(items)\n","\n","def support_response(user_text=\"\"):\n","    validations = [\n","        \"I hear you ‚Äî that feels heavy and valid.\",\n","        \"You're allowed to feel this; I'm with you.\",\n","        \"This is tough, and that doesn't make you weak.\"\n","    ]\n","    micro = [\n","        \"1) 3 deep breaths\\n2) Drink water\\n3) Do one 5-min step\",\n","        \"1) Name one feeling\\n2) Stretch 60s\\n3) Try 5 minutes of focused work\"\n","    ]\n","    return f\"{random.choice(validations)}\\n\\nTry this:\\n{random.choice(micro)}\"\n","\n","def reality_check(user_text=\"\"):\n","    punches = [\n","        \"Confidence is cute, action makes it real.\",\n","        \"Main character energy needs main character effort.\",\n","        \"You're hyped ‚Äî now channel it into one measurable thing.\"\n","    ]\n","    push = [\n","        \"Do ONE thing for 5 minutes now.\",\n","        \"Open a doc and write one paragraph.\",\n","        \"Start a 5-minute timer and begin. No perfection.\"\n","    ]\n","    return f\"{random.choice(punches)} üíú\\n\\n{random.choice(push)}\"\n","\n","print(\"Personality helpers ready.\")"]},{"cell_type":"markdown","id":"43332398","metadata":{"papermill":{"duration":0.006037,"end_time":"2025-12-01T21:08:36.720507","exception":false,"start_time":"2025-12-01T21:08:36.71447","status":"completed"},"tags":[]},"source":["**Cell 11 - Personality Helpers**\n","\n","Short, reusable helpers for tone and motivation.\n","\n","Includes\n","\n","Motivation-of-the-day\n","\n","Emotional support responses\n","\n","Reality checks\n","\n","Micro encouragement messages\n","\n","Why it matters\n","\n","These give Stepcom emotional depth and variety - key to keeping Gen Z users engaged."]},{"cell_type":"code","execution_count":12,"id":"c933aef7","metadata":{"execution":{"iopub.execute_input":"2025-12-01T21:08:36.733089Z","iopub.status.busy":"2025-12-01T21:08:36.732771Z","iopub.status.idle":"2025-12-01T21:08:36.737738Z","shell.execute_reply":"2025-12-01T21:08:36.736736Z"},"papermill":{"duration":0.012977,"end_time":"2025-12-01T21:08:36.7391","exception":false,"start_time":"2025-12-01T21:08:36.726123","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Console helper included (commented). Use chat UI (Gradio) for interactive demo.\n"]}],"source":["HELP = \"\"\"\n","StepCom Console Commands (for local debug only; the Gradio cell is the primary interface):\n","- add_habit <name> <good|bad>\n","- mark_habit_done <name>\n","- add_task <text>\n","- complete_task <text>\n","\"\"\"\n","print(\"Console helper included (commented). Use chat UI (Gradio) for interactive demo.\")"]},{"cell_type":"markdown","id":"cfc23b58","metadata":{"papermill":{"duration":0.005555,"end_time":"2025-12-01T21:08:36.75037","exception":false,"start_time":"2025-12-01T21:08:36.744815","status":"completed"},"tags":[]},"source":["**Cell 12 - (Optional) Console Mode**\n","\n","This is a non-UI testing interface.\n","\n","Why it's here\n","\n","Useful for debugging\n","\n","Helps judges verify agent logic without UI\n","\n","Left commented out so it doesn't block Kaggle runs"]},{"cell_type":"code","execution_count":13,"id":"feadfc45","metadata":{"execution":{"iopub.execute_input":"2025-12-01T21:08:36.763132Z","iopub.status.busy":"2025-12-01T21:08:36.762792Z","iopub.status.idle":"2025-12-01T21:08:44.547777Z","shell.execute_reply":"2025-12-01T21:08:44.546922Z"},"papermill":{"duration":7.793243,"end_time":"2025-12-01T21:08:44.549141","exception":false,"start_time":"2025-12-01T21:08:36.755898","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["* Running on local URL:  http://0.0.0.0:7860\n","* Running on public URL: https://1ca9aa90ad50b49813.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["<div><iframe src=\"https://1ca9aa90ad50b49813.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":[]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["import gradio as gr\n","from datetime import datetime\n","\n","CSS = r\"\"\"\n","/* Page + container */\n","body { background: linear-gradient(180deg,#06040c 0%, #0b0710 100%); color: #111111; font-family: Inter, system-ui, -apple-system, 'Segoe UI', Roboto, 'Helvetica Neue', Arial; }\n",".gradio-container { max-width:980px !important; margin: 18px auto; border-radius: 12px; padding: 14px; }\n","\n","/* Title & subtitle */\n",".title { font-size:3rem; font-weight:600; color:#7248C2; font-family: 'Inter', sans-serif; letter-spacing: -0.02em }             /* darker purple title */\n",".subtitle { color:#9068DE; margin-top:4px; font-size:13px; }           /* DARKER subtitle */\n","\n","/* Panel */\n",".section { background: #0f0816; padding:12px; border-radius:12px; margin-bottom:12px; box-shadow: 0 12px 30px rgba(0,0,0,0.6); }\n",".panel-title { color:#D6CBFF; font-weight:700; margin-bottom:8px; font-size:14px; }\n","\n","/* Buttons */\n",".btn-primary {\n","  background: #3B1F6B !important;   /* dark purple (Send) */\n","  color: #FFFFFF !important;        /* white text */\n","  border:1.5px solid #000 !important;\n","  border-radius:10px !important;\n","  padding:10px 16px !important;\n","  font-weight:700;\n","  box-shadow: 0 6px 18px rgba(59,31,107,0.25);\n","}\n",".btn-primary:hover { background:#4b2a8a !important; transform: translateY(-1px); }\n","\n","/* Make Micro-step and Clear darker and readable (previously ghost) */\n",".btn-ghost {\n","  background: #3B1F6B !important;   /* now dark purple like primary (but lighter shade optional) */\n","  color:#FFFFFF !important;         /* white text for readability */\n","  border:1.2px solid rgba(0,0,0,0.8) !important;\n","  border-radius:10px !important;\n","  padding:8px 12px !important;\n","  font-weight:700;\n","}\n",".btn-ghost:hover { background:#4b2a8a !important; }\n","\n","/* Inputs & chat bubbles */\n",".input-compact .input, .input-compact textarea { background: #FFFFFF !important; color: #000 !important; border-radius:8px; border: 1px solid #111 !important; }\n",".chat-bubble-user { background:#FFFFFF; color:#000; padding:10px 14px; border-radius:14px; display:inline-block; margin:6px 0; }\n",".chat-bubble-assistant { background: linear-gradient(90deg,#6F4AE2,#B99CFF); color:#fff; padding:10px 14px; border-radius:14px; display:inline-block; margin:6px 0; box-shadow: 0 10px 24px rgba(122,86,246,0.12); }\n","\n","/* Footer / small muted text (darker now) */\n",".small-muted { color:#9068DE; opacity:0.95; font-size:13px; }\n","\n","/* Placeholder text slightly darker for readability */\n",".input-compact ::placeholder { color: #ACA2C0 !important; opacity:1 !important; }\n","\n","/* Ensure footer text area visible */\n","footer { color: #9068DE !important; }\n","\"\"\"\n","\n","with gr.Blocks(css=CSS, title=\"Stepcom - Your AI Productivity Companion\") as app:\n","    # Header / movement title\n","    gr.HTML(\"\"\"\n","    <div style='display:flex;align-items:center;justify-content:space-between'>\n","      <div>\n","        <div class='title'>Stepcom</div>\n","        <div class='subtitle'>Your AI Productivity Companion - chat to get micro-plans, reality checks & habit help</div>\n","      </div>\n","    </div>\n","    \"\"\")\n","    gr.Markdown(\"\")  # spacer\n","\n","    # Chat column only (wide)\n","    with gr.Group(elem_classes=\"section\"):\n","        chat = gr.Chatbot(type=\"messages\", label=\"\")\n","        user_input = gr.Textbox(placeholder=\"Say something (e.g. 'I'm procrastinating', 'I keep scrolling', 'I can't start my assignment') - press send\", show_label=False, elem_classes=\"input-compact\")\n","        with gr.Row():\n","            send_btn = gr.Button(\"Send\", elem_classes=\"btn-primary\")\n","            micro_btn = gr.Button(\"Micro-step\", elem_classes=\"btn-ghost\")\n","            clear_btn = gr.Button(\"Clear\", elem_classes=\"btn-ghost\")\n","        gr.HTML(\"<div class='small-muted'>StepCom stores simple history & habit notes so it can follow up. All via chat.</div>\")\n","\n","    # Callback logic (unchanged)\n","    def send_message(user_text, history):\n","        history = history or []\n","        if not user_text or not user_text.strip():\n","            return history\n","        history.append({\"role\":\"user\",\"content\":user_text})\n","\n","        # A2A delegation (emotion/planning suggestions)\n","        a2a = controller_delegate_demo(user_text)\n","        if a2a:\n","            resp = a2a\n","        else:\n","            try:\n","                chat_obj = controller_chat.start_chat(history=[]) if hasattr(controller_chat, \"start_chat\") else controller_chat\n","                prompt = user_text + f\"\\n\\n[SESSION_MODE:{memory.get('meta',{}).get('mode','soft')}]\"\n","                if 'send_with_retries' in globals() and not USE_HTTP_RETRY:\n","                    r = send_with_retries(chat_obj, prompt)\n","                else:\n","                    r = chat_obj.send_message(prompt)\n","                resp = extract_text(r)\n","            except Exception as e:\n","                print(\"Controller call failed:\", e)\n","                resp = support_response(user_text) if any(k in user_text.lower() for k in [\"sad\",\"struggl\",\"can't\",\"cant\",\"lonely\",\"stressed\"]) else \"I couldn't reach my brain right now ‚Äî try rephrasing or say 'motivate me'.\"\n","\n","        memory.setdefault(\"meta\", {}).setdefault(\"a2a_logs\", []).append({\"ts\": datetime.now().isoformat(), \"prompt\": user_text[:500], \"response\": str(resp)[:1000]})\n","        save_json(MEMORY_PATH, memory)\n","        history.append({\"role\":\"assistant\",\"content\":resp})\n","        return history\n","\n","    send_btn.click(send_message, [user_input, chat], chat)\n","    user_input.submit(send_message, [user_input, chat], chat)\n","\n","    def micro_cb(history):\n","        history = history or []\n","        history.append({\"role\":\"assistant\",\"content\":\"Tiny step: set a 10-minute timer and do one focused thing. Say 'done' when you're back ‚Äî I'll celebrate.\"})\n","        return history\n","    micro_btn.click(micro_cb, [chat], chat)\n","\n","    clear_btn.click(lambda: [], None, chat)\n","\n","# Launch UI (will print shareable URL)\n","app.launch(server_name=\"0.0.0.0\", server_port=7860, share=True)"]},{"cell_type":"markdown","id":"ce60908d","metadata":{"papermill":{"duration":0.006127,"end_time":"2025-12-01T21:08:44.56155","exception":false,"start_time":"2025-12-01T21:08:44.555423","status":"completed"},"tags":[]},"source":["**Cell 13 - Gradio Chat UI (Primary User Experience)**\n","\n","This cell builds the entire Stepcom interface.\n","\n","Design goals\n","\n","Dark purple gradient background\n","\n","White chat bubbles\n","\n","Black button borders\n","\n","Clean, modern Gen Z aesthetic\n","\n","Chat-only interface (no task boxes, no habit forms)\n","\n","Features\n","\n","Real-time chat\n","\n","Micro-step quick button\n","\n","Clear history button\n","\n","Emotion + micro-plan agent routing\n","\n","Memory auto-saving\n","\n","A shareable public URL"]},{"cell_type":"code","execution_count":14,"id":"f37d1979","metadata":{"execution":{"iopub.execute_input":"2025-12-01T21:08:44.57578Z","iopub.status.busy":"2025-12-01T21:08:44.575271Z","iopub.status.idle":"2025-12-01T21:08:50.204881Z","shell.execute_reply":"2025-12-01T21:08:50.203787Z"},"papermill":{"duration":5.638757,"end_time":"2025-12-01T21:08:50.206495","exception":false,"start_time":"2025-12-01T21:08:44.567738","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Manifest, tests, and writeup template written to /kaggle/working/.\n"]}],"source":["OUT_DIR = \"/kaggle/working\"\n","MANIFEST_PATH = os.path.join(OUT_DIR, \"stepcom_manifest.json\")\n","TESTS_PATH = os.path.join(OUT_DIR, \"stepcom_selftests.json\")\n","WRITEUP_PATH = os.path.join(OUT_DIR, \"writeup_template.md\")\n","\n","def now(): return datetime.now().isoformat()\n","\n","manifest = {\n","    \"name\": \"StepCom\",\n","    \"type\": \"Concierge / Chat-first Productivity Companion\",\n","    \"description\": \"Chat-first Gen-Z friendly AI that offers micro-plans, motivational support, habit explanations, and reality checks.\",\n","    \"model_used\": MODEL_NAME,\n","    \"features\": {\n","        \"multi_agent\": [\"Controller\",\"EmotionAgent\",\"PlanAgent\"],\n","        \"tools\": [\"add_task\",\"complete_task\",\"add_goal\",\"add_habit\",\"mark_habit_done\",\"get_habits\",\"explain_habit_with_gemini\"],\n","        \"memory_path\": MEMORY_PATH,\n","        \"a2a_logs\": \"memory.meta.a2a_logs\",\n","        \"retry\": \"HttpRetryOptions if available else fallback send_with_retries\",\n","    },\n","    \"created_at\": now()\n","}\n","with open(MANIFEST_PATH, \"w\") as f:\n","    json.dump(manifest, f, indent=2)\n","\n","# simple tests (not exhaustive)\n","tests = {}\n","errors = []\n","try:\n","    t0 = f\"t-{int(time.time())}\"\n","    r = add_task(\"test \"+t0)\n","    tests['add_task'] = {'input': t0, 'result': r}\n","except Exception as e:\n","    tests['add_task'] = {'error': str(e)}\n","    errors.append(str(e))\n","\n","try:\n","    hname = f\"testhabit_{int(time.time())}\"\n","    r1 = add_habit(hname, 'bad')\n","    r2 = mark_habit_done(hname)\n","    try:\n","        explain_text = explain_habit_with_gemini(hname)\n","    except Exception as e:\n","        explain_text = f\"ERR: {e}\"\n","    tests['habit_flow'] = {'add': r1, 'done': r2, 'explain_preview': (explain_text or '')[:300]}\n","except Exception as e:\n","    tests['habit_flow'] = {'error': str(e)}\n","    errors.append(str(e))\n","\n","with open(TESTS_PATH, 'w') as f:\n","    json.dump({'tests': tests, 'errors': errors, 'generated_at': now()}, f, indent=2)\n","\n","writeup_md = f\"\"\"\n","# Stepcom ‚Äî Capstone Agent (Concierge/Chat-first)\n","\n","Short pitch:\n","Stepcom is a chat-first, Gen-Z oriented productivity companion that focuses on tiny, actionable steps rather than heavy task management. The UI is a single chat playground ‚Äî laziness-friendly by design.\n","\n","Architecture: Controller delegates to EmotionAgent & PlanAgent for empathy and micro-plans. Tools manage tasks/habits/goals in persisted memory.\n","\n","Run instructions: add your GOOGLE_API_KEY in Kaggle Secrets. Run all cells. Launch the Gradio UI (cell 13) and use the chat to interact.\n","\n","\"\"\"\n","with open(WRITEUP_PATH, 'w') as f:\n","    f.write(writeup_md)\n","\n","print(\"Manifest, tests, and writeup template written to /kaggle/working/.\")\n"]},{"cell_type":"markdown","id":"882d57ba","metadata":{"papermill":{"duration":0.006386,"end_time":"2025-12-01T21:08:50.220654","exception":false,"start_time":"2025-12-01T21:08:50.214268","status":"completed"},"tags":[]},"source":["**Cell 14 - Packaging (Manifest, Self-tests & Writeup Template)**\n","\n","This cell produces all files needed for Kaggle Capstone submission:\n","\n","Self-tests check\n","\n","Adding tasks\n","\n","Creating habits\n","\n","Marking habits done\n","\n","Habit explanation\n","\n","A2A agent pipeline\n","\n","Why this matters\n","\n","Kaggle requires:\n","\n","A manifest\n","\n","Tests\n","\n","A write-up\n","\n","This cell builds all necessary deliverables automatically."]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":28.203237,"end_time":"2025-12-01T21:08:52.846307","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-12-01T21:08:24.64307","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}